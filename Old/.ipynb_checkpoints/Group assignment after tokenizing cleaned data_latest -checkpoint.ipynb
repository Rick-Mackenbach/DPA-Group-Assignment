{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "import sklearn\n",
    "import sklearn.metrics.pairwise\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import adjusted_rand_score\n",
    "from nltk import word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/u990505/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /home/u990505/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_text(text, stem=True):\n",
    "    \"\"\" Tokenize text and stem words removing punctuation \"\"\"\n",
    "    text = text.translate(string.punctuation)\n",
    "    tokens = word_tokenize(text)\n",
    " \n",
    "    if stem:\n",
    "        stemmer = PorterStemmer()\n",
    "        tokens = [stemmer.stem(t) for t in tokens]\n",
    " \n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "descriptions = []\n",
    "\n",
    "with open('descriptions.txt', encoding = \"utf8\") as f:\n",
    "    for line in f:\n",
    "        text = line.lower()                                       ## Lowercase all characters\n",
    "        text = text.replace(\"[comma]\",\" \")                        ## Replace [commas] with empty space\n",
    "        for ch in text:\n",
    "            if ch < \"0\" or (ch < \"a\" and ch > \"9\") or ch > \"z\":   ## The cleaning operation happens here, remove all special characters\n",
    "                text = text.replace(ch,\" \")\n",
    "        text = ' '.join(text.split())                             ## Remove double spacing from sentences\n",
    "        descriptions.append(text)\n",
    "dataSet = numpy.array(descriptions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What our Tf-Idf looks like: \n",
      "\n",
      "  (0, 3085)\t0.180162937562\n",
      "  (0, 1351)\t0.108587000666\n",
      "  (0, 3257)\t0.300162482365\n",
      "  (0, 2585)\t0.34043262183\n",
      "  (0, 2139)\t0.113064162116\n",
      "  (0, 4024)\t0.218541466991\n",
      "  (0, 1981)\t0.255811941541\n",
      "  (0, 3626)\t0.316791499169\n",
      "  (0, 1152)\t0.243157539988\n",
      "  (0, 4070)\t0.268466343093\n",
      "  (0, 1073)\t0.304137097616\n",
      "  (0, 2120)\t0.268466343093\n",
      "  (0, 1687)\t0.0661908689456\n",
      "  (0, 1200)\t0.263831802395\n",
      "  (0, 1473)\t0.316791499169\n",
      "  (0, 1117)\t0.164803210907\n",
      "  (0, 4092)\t0.161675882415\n"
     ]
    }
   ],
   "source": [
    "vectorizer = TfidfVectorizer(stop_words='english')\n",
    "TfIdf_dataSet = vectorizer.fit_transform(dataSet)\n",
    "print(\"What our Tf-Idf looks like: \")\n",
    "print()\n",
    "print(TfIdf_dataSet[0:1])\n",
    "\n",
    "vectorVocab = vectorizer._validate_vocabulary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.          0.06419899  0.01454109 ...,  0.00629138  0.06862054\n",
      "   0.07042177]\n",
      " [ 0.06419899  1.          0.06743771 ...,  0.04726818  0.06877843\n",
      "   0.04734656]\n",
      " [ 0.01454109  0.06743771  1.         ...,  0.00565678  0.065617\n",
      "   0.02817174]\n",
      " ..., \n",
      " [ 0.00629138  0.04726818  0.00565678 ...,  1.          0.00482428\n",
      "   0.00497692]\n",
      " [ 0.06862054  0.06877843  0.065617   ...,  0.00482428  1.          0.07985904]\n",
      " [ 0.07042177  0.04734656  0.02817174 ...,  0.00497692  0.07985904  1.        ]]\n"
     ]
    }
   ],
   "source": [
    "cosineSimilarity = sklearn.metrics.pairwise.cosine_similarity(TfIdf_dataSet)\n",
    "print(cosineSimilarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[   0 1454   65 ..., 1179  883  317]\n",
      " [   1  556  549 ...,  883  857  853]\n",
      " [   2  342    4 ..., 1007  373 1303]\n",
      " ..., \n",
      " [1477 1372  210 ...,  687 1011  575]\n",
      " [1478  967  706 ...,  865  275 1365]\n",
      " [1479 1341 1144 ...,  676 1178  690]]\n",
      "\n",
      "[[   0 1454   65   66  406]\n",
      " [   1  556  549 1373  944]\n",
      " [   2  342    4  288  379]\n",
      " ..., \n",
      " [1477 1372  210  902  681]\n",
      " [1478  967  706  669 1084]\n",
      " [1479 1341 1144  500  773]]\n"
     ]
    }
   ],
   "source": [
    "numpy.fill_diagonal(cosineSimilarity,1.1)\n",
    "cosineSimilaritySorted = numpy.argsort((-1*(cosineSimilarity)),axis=1)\n",
    "print(cosineSimilaritySorted)\n",
    "cosineSimilaritySorted = numpy.argsort((-1*(cosineSimilarity)),axis=1)\n",
    "top5similar = (cosineSimilaritySorted[:,0:5])\n",
    "print()\n",
    "print(top5similar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "numpy.savetxt(\"results.csv\", top5similar.astype(int), fmt='%i', delimiter=\",\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
