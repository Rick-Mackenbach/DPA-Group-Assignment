{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "import scipy\n",
    "import scipy.sparse\n",
    "import sklearn\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.cluster import KMeans\n",
    "import sklearn.metrics.pairwise\n",
    "import string\n",
    "import collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import adjusted_rand_score\n",
    "\n",
    "from nltk import word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_text(text, stem=True):\n",
    "    \"\"\" Tokenize text and stem words removing punctuation \"\"\"\n",
    "    text = text.translate(string.punctuation)\n",
    "    tokens = word_tokenize(text)\n",
    " \n",
    "    if stem:\n",
    "        stemmer = PorterStemmer()\n",
    "        tokens = [stemmer.stem(t) for t in tokens]\n",
    " \n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "descriptions = []\n",
    "\n",
    "with open('coco_val.txt', encoding = \"utf8\") as f:\n",
    "    for line in f:\n",
    "        text = line.lower()                                       ## Lowercase all characters\n",
    "        text = text.replace(\"[comma]\",\" \")                        ## Replace [commas] with empty space\n",
    "        for ch in text:\n",
    "            if ch < \"0\" or (ch < \"a\" and ch > \"9\") or ch > \"z\":   ## The cleaning operation happens here, remove all special characters\n",
    "                text = text.replace(ch,\" \")\n",
    "        text = ' '.join(text.split())                             ## Remove double spacing from sentences\n",
    "        descriptions.append(text)\n",
    "dataSet = numpy.array(descriptions[0:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What our Tf-Idf looks like: \n",
      "\n",
      "  (0, 35)\t0.44471458766073974\n",
      "  (0, 93)\t0.2992971973799435\n",
      "  (0, 76)\t0.44471458766073974\n",
      "  (0, 206)\t0.3454517762690821\n",
      "  (0, 147)\t0.44471458766073974\n",
      "  (0, 222)\t0.44471458766073974\n"
     ]
    }
   ],
   "source": [
    "vectorizer = TfidfVectorizer(tokenizer=process_text, stop_words='english')\n",
    "TfIdf_dataSet = vectorizer.fit_transform(dataSet)\n",
    "print(\"What our Tf-Idf looks like: \")\n",
    "print()\n",
    "print(TfIdf_dataSet[0:1])\n",
    "\n",
    "vectorVocab = vectorizer._validate_vocabulary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.         0.22252321 0.19205792 ... 0.         0.         0.        ]\n",
      " [0.22252321 1.         0.33283069 ... 0.         0.         0.        ]\n",
      " [0.19205792 0.33283069 1.         ... 0.         0.         0.        ]\n",
      " ...\n",
      " [0.         0.         0.         ... 1.         0.16957961 0.        ]\n",
      " [0.         0.         0.         ... 0.16957961 1.         0.13207091]\n",
      " [0.         0.         0.         ... 0.         0.13207091 1.        ]]\n"
     ]
    }
   ],
   "source": [
    "cosineSimilarity = sklearn.metrics.pairwise.cosine_similarity(TfIdf_dataSet)\n",
    "print(cosineSimilarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0  4  1 ... 33 31 99]\n",
      " [ 1  2 12 ... 33 31 99]\n",
      " [ 2  3  4 ... 33 31 99]\n",
      " ...\n",
      " [97 95 98 ... 26 24 99]\n",
      " [98 96 25 ... 26 50 49]\n",
      " [99 94 93 ... 25 23 49]]\n",
      "\n",
      "[[ 0  4  1  2  3]\n",
      " [ 1  2 12  3  4]\n",
      " [ 2  3  4  1 12]\n",
      " [ 3  2  4  1 12]\n",
      " [ 4  2  3  1  0]\n",
      " [ 5  6  7  9  8]\n",
      " [ 6  7  5  9  8]\n",
      " [ 7  6  5 91  9]\n",
      " [ 8  9 20  6 15]\n",
      " [ 9  8 18 82 80]\n",
      " [10 11 53 12 14]\n",
      " [11 10 12 14 13]\n",
      " [12 13 14  1 11]\n",
      " [13 12 14 11 10]\n",
      " [14 12 13 11 10]\n",
      " [15 30 32 18 49]\n",
      " [16 15 19 18 58]\n",
      " [17 19 15 24 18]\n",
      " [18 15  9 44 58]\n",
      " [19 17 16 15 53]\n",
      " [20 23 21 40 22]\n",
      " [21 20 41 23 40]\n",
      " [22 23 20 24 21]\n",
      " [23 22 20 24 21]\n",
      " [24 23 22 15 18]\n",
      " [25 27 65 29 98]\n",
      " [26 28 29 65 27]\n",
      " [27 25 65 26 28]\n",
      " [28 26 29 65 27]\n",
      " [29 26 28 65 69]\n",
      " [30 32 15 40 44]\n",
      " [31 82 83 87 15]\n",
      " [32 30 15 40 44]\n",
      " [33 43 34 15 24]\n",
      " [34 43 44 15 33]\n",
      " [35 36 39 38 37]\n",
      " [36 35 39 38 37]\n",
      " [37 39 36 35 38]\n",
      " [38 39 36 35 37]\n",
      " [39 38 36 35 37]\n",
      " [40 20 30 32 15]\n",
      " [41 21 51 52 47]\n",
      " [42 44 43 30 40]\n",
      " [43 44 34 42 15]\n",
      " [44 43 42 30 34]\n",
      " [45 46 47 49 48]\n",
      " [46 47 45 49 48]\n",
      " [47 46 45 49 48]\n",
      " [48 49 46 15 47]\n",
      " [49 45 46 48 15]\n",
      " [50 52 51 54 39]\n",
      " [51 52 50 54 41]\n",
      " [52 51 50 54 49]\n",
      " [53 10 52 16 19]\n",
      " [54 52 51 72 50]\n",
      " [55 59 58 57 56]\n",
      " [56 57 59 58 63]\n",
      " [57 58 59 56 55]\n",
      " [58 57 15 18 59]\n",
      " [59 55 57 56 58]\n",
      " [60 64 84 18 94]\n",
      " [61 63 34 40  0]\n",
      " [62 67 64 44 80]\n",
      " [63 56 64 61  0]\n",
      " [64 60 84 63 62]\n",
      " [65 69 68 29 26]\n",
      " [66 69 65 68 74]\n",
      " [67 69 65 68 29]\n",
      " [68 69 65 66 29]\n",
      " [69 65 68 74 66]\n",
      " [70 74 72 28 71]\n",
      " [71 74 72 73 69]\n",
      " [72 74 73 71 69]\n",
      " [73 72 74 71 70]\n",
      " [74 72 71 73 69]\n",
      " [75 88 46 47 45]\n",
      " [76 78 77 79 75]\n",
      " [77 79 76 78 75]\n",
      " [78 76 77 79 75]\n",
      " [79 77 76 78 75]\n",
      " [80 88 82 85 84]\n",
      " [81 80 82 88 87]\n",
      " [82 80 88 87 83]\n",
      " [83 87 82 31 86]\n",
      " [84 80 82 60 88]\n",
      " [85 80 88 86 84]\n",
      " [86 85 83 80 87]\n",
      " [87 83 82 80 31]\n",
      " [88 80 82 85 75]\n",
      " [89 36 35 18 39]\n",
      " [90 92 91 39 38]\n",
      " [91 90  7 97 52]\n",
      " [92 90 39 93 38]\n",
      " [93 94 92 99 95]\n",
      " [94 99 93 69 39]\n",
      " [95 96 38 69 94]\n",
      " [96 95 98 38 21]\n",
      " [97 95 98 90 91]\n",
      " [98 96 25 38 95]\n",
      " [99 94 93 16 98]]\n"
     ]
    }
   ],
   "source": [
    "numpy.fill_diagonal(cosineSimilarity,1.1)\n",
    "cosineSimilaritySorted = numpy.argsort((-1*(cosineSimilarity)),axis=1)\n",
    "print(cosineSimilaritySorted)\n",
    "cosineSimilaritySorted = numpy.argsort((-1*(cosineSimilarity)),axis=1)\n",
    "top5similar = (cosineSimilaritySorted[:,0:5])\n",
    "print()\n",
    "print(top5similar)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
