{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/rickmackenbach/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/rickmackenbach/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy\n",
    "import sklearn\n",
    "import sklearn.metrics.pairwise\n",
    "from sklearn.metrics.pairwise import pairwise_distances\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "import string\n",
    "import collections\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import HashingVectorizer\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import adjusted_rand_score\n",
    "from nltk import word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.corpus import stopwords\n",
    "from pprint import pprint\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After running first results, the following sentence was found : \n",
      "\n",
      "rwevfderdcerfadwerfdewadrwevfderdcerfadwerfdewadrwevfderdcerfadwerfdewadrwevfderdcerfadwerfdewadrwevfderdcerfadwerfdewadrwevfderdcerfadwerfdewadrwevfderdcerfadwerfdewadrwevfderdcerfadwerfdewadrwevfderdcerfadwerfdewadrwevfderdcerfadwerfdewadrwevfderdcerfadwerfdewadrwevfderdcerfadwerfdewadrwevfderdcerfadwerfdewad rwevfderdcerfadwerfdewad rwevfderdcerfadwerfdewad rwevfderdcerfadwerfdewad rwevfderdcerfadwerfdewad rwevfderdcerfadwerfdewad rwevfderdcerfadwerfdewad rwevfderdcerfadwerfdewad rwevfderdcerfadwerfdewad rwevfderdcerfadwerfdewad rwevfderdcerfadwerfdewad rwevfderdcerfadwerfdewad rwevfderdcerfadwerfdewadrwevfderdcerfadwerfdewadrwevfderdcerfadwerfdewadrwevfderdcerfadwerfdewadrwevfderdcerfadwerfdewadrwevfderdcerfadwerfdewadrwevfderdcerfadwerfdewadrwevfderdcerfadwerfdewadrwevfderdcerfadwerfdewadrwevfderdcerfadwerfdewadrwevfderdcerfadwerfdewadrwevfderdcerfadwerfdewadrwevfderdcerfadwerfdewadrwevfderdcerfadwerfdewadrwevfderdcerfadwerfdewadrwevfderdcerfadwerfdewadrwevfderdcerfadwerfdewad rwevfderdcerfadwerfdewad rwevfderdcerfadwerfdewad rwevfderdcerfadwerfdewad rwevfderdcerfadwerfdewad rwevfderdcerfadwerfdewad rwevfderdcerfadwerfdewad rwevfderdcerfadwerfdewad rwevfderdcerfadwerfdewad rwevfderdcerfadwerfdewad rwevfderdcerfadwerfdewad rwevfderdcerfadwerfdewad\n",
      "\n",
      "\n",
      "Although this sentence is not meaningful, it will remain in the dataset in order to have consistent results.\n"
     ]
    }
   ],
   "source": [
    "## Set an empty list variable\n",
    "\n",
    "descriptions = []\n",
    "\n",
    "with open('descriptions.txt', encoding = \"utf8\") as f:\n",
    "    for line in f:\n",
    "        text = line.lower()                                       ## Lowercase all characters\n",
    "        text = text.replace(\"[comma]\",\" \")                        ## Replace [commas] with empty space\n",
    "        for ch in text:\n",
    "            if ch < \"0\" or (ch < \"a\" and ch > \"9\") or ch > \"z\":   ## The cleaning operation happens here, remove all special characters\n",
    "                text = text.replace(ch,\" \")\n",
    "        text = ' '.join(text.split())                             ## Remove double spacing from sentences\n",
    "        descriptions.append(text)\n",
    "dataSet = numpy.array(descriptions)\n",
    "\n",
    "print('After running first results, the following sentence was found : ')\n",
    "print()\n",
    "print(dataSet[496])\n",
    "print()\n",
    "print()\n",
    "print('Although this sentence is not meaningful, it will remain in the dataset in order to have consistent results.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(max_df=0.5, min_df=2, stop_words='english', max_features=1000, use_idf=True)\n",
    "TfIdf_dataSet = vectorizer.fit_transform(dataSet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "LSA = TruncatedSVD(100)\n",
    "LSAData = LSA.fit_transform(TfIdf_dataSet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[[   0   66  894 1376  406]\n",
      " [   1  549  556  506  206]\n",
      " [   2  342  405  646 1388]\n",
      " ...\n",
      " [1477  392 1372  859  530]\n",
      " [1478  967  216  625  579]\n",
      " [1479  788 1341  553 1144]]\n"
     ]
    }
   ],
   "source": [
    "cosineSimilarity = sklearn.metrics.pairwise.cosine_similarity(LSAData)\n",
    "numpy.fill_diagonal(cosineSimilarity,1.1)\n",
    "cosineSimilaritySorted = numpy.argsort((-1*(cosineSimilarity)),axis=1)\n",
    "top5similar = (cosineSimilaritySorted[:,0:5])\n",
    "print()\n",
    "print(top5similar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "red hair a little lower than the ears big face a little weirdly shaped around the jaw freckles he looks like he had a hard childhood and isn t a happy person he probably has a lot of repressed feeling or the photographer didn t get him on a good day\n",
      "this is a white male with red hair and blue eyes his hair is shaggy and has a little facial stubble this person is a student he might be a little over weight he looks a little angry\n"
     ]
    }
   ],
   "source": [
    "print(dataSet[2])\n",
    "print(dataSet[342])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "numpy.savetxt(\"results3.csv\", top5similar.astype(int), fmt='%i', delimiter=\",\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
